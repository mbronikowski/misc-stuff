{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8591c73d-a814-4df3-b090-b37b065391eb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a46a18-0319-4cb1-9675-580f2cf10ff4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "import astroalign as aa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from astropy.time import Time\n",
    "from astropy.table import Table, Column\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137eb26e-8362-4eb3-be48-6c1e61f0fce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current working directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7df6aac-b582-4d55-8eec-e30f499b2d82",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Set up data paths, output paths etc. These are the user-configurable parameters for data reduction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8851bdf1-a24c-4efd-b756-38788c821bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sci_path = \"\"\n",
    "bias_path = os.path.join(raw_sci_path, \"calib\")  # This notebook is setup for data in the main directory, and calibration frames\n",
    "dark_path = os.path.join(raw_sci_path, \"calib\")  # in the 'calib' subfolder. Change to suit your needs.\n",
    "flat_path = os.path.join(raw_sci_path, \"calib\")\n",
    "\n",
    "master_path = os.path.join(raw_sci_path, \"masters\")  # Folder in which master frames are created and in which the script looks for masters.\n",
    "calibrated_path = os.path.join(raw_sci_path, \"calibrated\")  # Calibrated frames go here and are taken from here for stacking.\n",
    "stacked_path = os.path.join(raw_sci_path, \"stacked\")  # Stacked frames go here.\n",
    "\n",
    "do_image_calibration = True\n",
    "do_image_stacking = True\n",
    "stack_target_names = None    # None to stack everything; iterable of strings with names to only stack certain targets\n",
    "\n",
    "use_ready_masters = {\n",
    "    \"bias\": False,\n",
    "    \"dark\": False,\n",
    "    \"flat\": False\n",
    "    }\n",
    "\n",
    "# Set these to None if the data folder only contains one fits file category\n",
    "\n",
    "science_regex = None\n",
    "\n",
    "dark_regex = r\"^dark\"\n",
    "bias_regex = r\"^bias_BIAS\"\n",
    "flat_regex = r\"_FLAT\"\n",
    "\n",
    "# If using ready Master files, use this to configure how the script recognizes the files in the masters directory\n",
    "master_bias_regex = r\"[bB]ias\"\n",
    "master_dark_regex = r\"[dD]ark\"\n",
    "master_flat_regex = r\"[fF]lat\"\n",
    "\n",
    "# Misc config\n",
    "\n",
    "fits_shape = 3194, 4788  # GoChile binning 2 shape\n",
    "observer_name = \"Mateusz Bronikowski\"  # Goes into FITS headers. Leave None to leave original observer in headers\n",
    "\n",
    "new_dark_scale = 60.  # Exposure time to which to scale any new master darks. Existing master darks will be used based on header data\n",
    "\n",
    "masters_dtype = np.float32  # For newly created master bias and dark, not reused masters. Master flats will always be float32.\n",
    "sci_frame_dtype = np.float32  # dtype to save scientific frames in\n",
    "stacked_dtype = np.float32\n",
    "\n",
    "fits_extension = \".FIT\"  # For finding FITS files created by the telescope, I can't be bothered making it automatic. Sorry!\n",
    "\n",
    "fix_lowercase_gaia = True  # Replace lowercase \"gaia\" in Gaia Alerts target names with uppercase in headers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44df140-67b4-4bd6-a5e8-1ecf54efe190",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "Here we define some useful functions and hidden parameters, create missing folders etc. The user doesn't need to interact with this section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c1abd1-6bbd-41e7-a015-0cf53e1fd206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_fits_files(directory, regex_pattern):\n",
    "    # Create the full path pattern to match all .fits files\n",
    "    pattern = os.path.join(directory, '*' + fits_extension)\n",
    "    # List all .fits files in the directory\n",
    "    all_fits_files = glob.glob(pattern)\n",
    "\n",
    "    if regex_pattern is None:\n",
    "        return all_fits_files\n",
    "    \n",
    "    # Compile the regex pattern\n",
    "    regex = re.compile(regex_pattern)\n",
    "    # Filter files that match the regex pattern\n",
    "    matched_files = [f for f in all_fits_files if regex.search(os.path.basename(f))]\n",
    "    \n",
    "    return matched_files\n",
    "\n",
    "\n",
    "def curr_iso_time_str():\n",
    "    return datetime.now().isoformat()[:19]    # Cut at seconds. GoChile won't require a higher precision anyway\n",
    "\n",
    "\n",
    "def jd_to_iso(jd):\n",
    "    time_jd = Time(jd, format='jd')\n",
    "    iso_jd = time_jd.to_value('iso', subfmt='date_hms')\n",
    "    return iso_jd[:19].replace(\" \", \"T\")    # Use YYYY-MM-DDThh:mm:ss instead of ISO format\n",
    "\n",
    "\n",
    "def mjd_to_iso(mjd):\n",
    "    time_mjd = Time(mjd, format='mjd')\n",
    "    iso_mjd = time_mjd.to_value('iso', subfmt='date_hms')\n",
    "    return iso_jd[:19].replace(\" \", \"T\")    # Use YYYY-MM-DDThh:mm:ss instead of ISO format\n",
    "\n",
    "\n",
    "def preview_image(image_array, cmap='gray', sigma_low=3, sigma_high=10, title=\"Image preview\"):\n",
    "    # Compute the mean and standard deviation of the image\n",
    "    mean = np.mean(image_array)\n",
    "    std = np.std(image_array)\n",
    "    \n",
    "    # Set the lower and upper bounds based on sigma\n",
    "    lower_bound = mean - sigma_low * std\n",
    "    upper_bound = mean + sigma_high * std\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = plt.gca()\n",
    "    plt.imshow(image_array, cmap=cmap, vmin=lower_bound, vmax=upper_bound, aspect='equal')\n",
    "\n",
    "    plt.colorbar(label='Pixel value')\n",
    "    ax.set_title(title)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# This is needed to fix FITS headers, otherwise the data type won't match the header.\n",
    "dtype_to_bitpix = {\n",
    "    np.int16: 16,\n",
    "    np.int32: 32,\n",
    "    np.float32: -32,\n",
    "    np.float64: -64,\n",
    "    np.uint8: 8,\n",
    "    np.int8: 8,\n",
    "    np.uint16: 16,\n",
    "    np.uint32: 32,\n",
    "}\n",
    "\n",
    "for path in (master_path, calibrated_path):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "if not os.path.exists(stacked_path) and do_image_stacking:\n",
    "    os.mkdir(stacked_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece291a1-049f-4f97-9481-f53be0d5fe03",
   "metadata": {},
   "source": [
    "# Load and calibrate\n",
    "\n",
    "Load up the scientific and calibration frames, then calibrate the frames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80871a69-051d-4706-b295-bd6dc3d7d913",
   "metadata": {},
   "source": [
    "## Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85997475-a6a3-494a-a6c3-f23bdd502343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_master_bias():\n",
    "    bias_fits = list_fits_files(bias_path, bias_regex)\n",
    "\n",
    "    all_data = np.empty((len(bias_fits), fits_shape[0], fits_shape[1]), dtype=np.float64)\n",
    "    for idx, filepath in enumerate(bias_fits):\n",
    "        # TODO: Add sensor temperature check and warning\n",
    "        all_data[idx, :, :] = fits.getdata(filepath)\n",
    "        \n",
    "\n",
    "    master_data, _, _ = sigma_clipped_stats(all_data, axis=0)  # 3-sigma clipped average\n",
    "    np.clip(master_data, 0, 65535, out=master_data)\n",
    "    master_data = master_data.astype(masters_dtype)\n",
    "    hdr = fits.getheader(bias_fits[0]).copy()    \n",
    "    if observer_name is not None:\n",
    "        hdr['OBSERVER'] = observer_name    \n",
    "    hdr[\"NFRAMES\"] = len(bias_fits)\n",
    "    hdr['BITPIX'] = dtype_to_bitpix[masters_dtype]\n",
    "    hdr[\"NFRAMES\"] = len(bias_fits)\n",
    "    hdr['COMBTYPE'] = 'SIGCLIP'\n",
    "    hdr['SIGCLIP'] = '3'\n",
    "    hdr.remove('BSCALE', ignore_missing=True)\n",
    "    hdr.remove('BZERO', ignore_missing=True)\n",
    "    hdr.add_history('3-sigma clipped mean combined')\n",
    "    hdu = fits.PrimaryHDU(master_data)\n",
    "    hdu.header = hdr\n",
    "    output_path = os.path.join(master_path, \"Master_Bias\" + fits_extension)\n",
    "    hdu.writeto(output_path, overwrite=True)\n",
    "    return master_data\n",
    "\n",
    "\n",
    "if use_ready_masters['bias']:\n",
    "    path_set = list_fits_files(master_path, master_bias_regex)\n",
    "    if len(path_set) != 1:\n",
    "        raise ValueError(f\"Found {len(path_set)} files in masters directory, make sure there is only one file which matches master_bias_regex!\")\n",
    "    master_bias = fits.getdata(path_set[0])\n",
    "else:\n",
    "    master_bias = create_master_bias()\n",
    "\n",
    "print(f\"Minimum value: {np.min(master_bias)}; maximum value: {np.max(master_bias)}\")\n",
    "preview_image(master_bias, cmap='gray', sigma_low=3, sigma_high=3, title=\"Master Bias frame\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00117e15-ce7f-4308-83ca-3029d104ac06",
   "metadata": {},
   "source": [
    "# Dark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca0397e-0d93-4e14-9047-a8cd1e814691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_master_dark():\n",
    "    dark_fits = list_fits_files(dark_path, dark_regex)\n",
    "\n",
    "    all_data = np.empty((len(dark_fits), fits_shape[0], fits_shape[1]), dtype=np.float64)\n",
    "    exptimes = np.empty(len(dark_fits))\n",
    "    for idx, filepath in enumerate(dark_fits):\n",
    "        # TODO: Add sensor temperature check and warning\n",
    "        all_data[idx, :, :] = fits.getdata(filepath)\n",
    "        exptimes[idx] = float(fits.getheader(dark_fits[idx])[\"EXPTIME\"])\n",
    "        all_data[idx, :, :] -= master_bias\n",
    "        all_data[idx, :, :] *= new_dark_scale / exptimes[idx]\n",
    "    \n",
    "    master_data, _, _ = sigma_clipped_stats(all_data, axis=0)  # 3-sigma clipped average\n",
    "    np.clip(master_data, 0, 65535, out=master_data)\n",
    "    master_data = master_data.astype(masters_dtype)\n",
    "    hdr = fits.getheader(dark_fits[0]).copy()\n",
    "    hdr['BITPIX'] = dtype_to_bitpix[masters_dtype]\n",
    "    if observer_name is not None:\n",
    "        hdr['OBSERVER'] = observer_name    \n",
    "    hdr[\"NFRAMES\"] = len(dark_fits)\n",
    "    hdr['COMBTYPE'] = 'SIGCLIP'\n",
    "    hdr['SIGCLIP'] = '3'\n",
    "    hdr.remove('BSCALE', ignore_missing=True)\n",
    "    hdr.remove('BZERO', ignore_missing=True)\n",
    "    hdr.add_history('Bias subtraction performed')\n",
    "    hdr.add_history('3-sigma clipped mean combined')\n",
    "    hdr['EXPTIME'] = str(round(new_dark_scale, 3))\n",
    "    hdr['EXPOSURE'] = str(round(new_dark_scale, 3))\n",
    "    hdu = fits.PrimaryHDU(master_data)\n",
    "    hdu.header = hdr\n",
    "    output_path = os.path.join(master_path, \"Master_Dark\" + fits_extension)\n",
    "    hdu.writeto(output_path, overwrite=True)\n",
    "    return master_data\n",
    "\n",
    "\n",
    "if use_ready_masters['dark']:\n",
    "    path_set = list_fits_files(master_path, master_dark_regex)\n",
    "    if len(path_set) != 1:\n",
    "        raise ValueError(f\"Found {len(path_set)} files in masters directory, make sure there is only one file which matches master_dark_regex!\")\n",
    "    master_dark = fits.getdata(path_set[0])\n",
    "    dark_scale = float(fits.getheader(path_set[0])['EXPTIME'])\n",
    "else:\n",
    "    master_dark, dark_scale = create_master_dark(), new_dark_scale\n",
    "\n",
    "print(f\"Minimum value: {np.min(master_dark)}; maximum value: {np.max(master_dark)}\")\n",
    "preview_image(master_dark, cmap='gray', sigma_low=3, sigma_high=10, title=\"Master Dark frame\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a932f7-280c-4366-be6f-38e5fdf0d952",
   "metadata": {},
   "source": [
    "# Flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3410a74f-ca6e-4fd8-80c3-7ec53ce33ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_master_flat():\n",
    "    flat_fits = list_fits_files(flat_path, flat_regex)\n",
    "    filters_files = {}\n",
    "    for filename in flat_fits:\n",
    "        filter_name = fits.getheader(filename).copy()['FILTER']\n",
    "        try:\n",
    "            filters_files[filter_name].append(filename)\n",
    "        except KeyError:\n",
    "            filters_files[filter_name] = []\n",
    "\n",
    "    all_data = {}\n",
    "    for filter_name in filters_files.keys():\n",
    "        flat_data = np.empty((len(filters_files[filter_name]), fits_shape[0], fits_shape[1]), dtype=np.float32)\n",
    "        for idx, filename in enumerate(filters_files[filter_name]):\n",
    "            flat_data[idx, :, :] = fits.getdata(filename)  # Load frames\n",
    "            exptime = float(fits.getheader(filename)[\"EXPTIME\"])  # Get exposure time for dark correction\n",
    "            flat_data[idx, :, :] -= master_bias  # Bias correction\n",
    "            flat_data[idx, :, :] -= master_dark * exptime / dark_scale  # Dark correction\n",
    "            flat_data[idx, :, :] /= np.median(flat_data[idx, :, :])  # normalize\n",
    "        all_data[filter_name], _, _ = sigma_clipped_stats(flat_data, axis=0)\n",
    "        np.clip(all_data[filter_name], 0, 65535, out=all_data[filter_name])\n",
    "        all_data[filter_name] = all_data[filter_name].astype(masters_dtype)\n",
    "        hdr = fits.getheader(filters_files[filter_name][0]).copy()\n",
    "        hdr['BITPIX'] = dtype_to_bitpix[masters_dtype]\n",
    "        if observer_name is not None:\n",
    "            hdr['OBSERVER'] = observer_name\n",
    "        hdr[\"NFRAMES\"] = len(filters_files[filter_name])\n",
    "        hdr['COMBTYPE'] = 'SIGCLIP'\n",
    "        hdr['SIGCLIP'] = '3'\n",
    "        hdr.remove('BSCALE', ignore_missing=True)\n",
    "        hdr.remove('BZERO', ignore_missing=True)\n",
    "        hdr.add_history('Bias subtraction performed')\n",
    "        hdr.add_history('Dark subtraction performed')\n",
    "        hdr.add_history('3-sigma clipped mean combined')\n",
    "        hdu = fits.PrimaryHDU(all_data[filter_name])\n",
    "        hdu.header = hdr\n",
    "        safe_filter_name = filter_name.replace('/', '').replace(' ', '_')\n",
    "        output_path = os.path.join(master_path, \"Master_Flat_\" + safe_filter_name + fits_extension)\n",
    "        hdu.writeto(output_path, overwrite=True)\n",
    "\n",
    "    return all_data\n",
    "\n",
    "\n",
    "if use_ready_masters['flat']:\n",
    "    path_set = list_fits_files(master_path, master_flat_regex)\n",
    "    master_flat = {}\n",
    "    for path in path_set:\n",
    "        filter_name = fits.getheader(path)['FILTER'] \n",
    "        master_flat[filter_name] = fits.getdata(path)\n",
    "else:\n",
    "    master_flat = create_master_flat()\n",
    "\n",
    "for flat_filter in master_flat.keys():\n",
    "    print(f\"Flat filter {flat_filter}. Minimum value: {np.min(master_flat[flat_filter])}; maximum value: {np.max(master_flat[flat_filter])}\")\n",
    "    preview_image(master_flat[flat_filter], cmap='gray', sigma_low=3, sigma_high=3, title=f\"Master Flat frame, filter: {flat_filter}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8d62f3-ceff-427c-9cf2-03fcb7d66f07",
   "metadata": {},
   "source": [
    "# Science frame calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad4417a-b773-4070-b546-f9dc40612791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calib_science_frames():\n",
    "    science_fits_paths = list_fits_files(raw_sci_path, science_regex)\n",
    "\n",
    "    for fits_path in science_fits_paths:\n",
    "        sci_hdr = fits.getheader(fits_path)\n",
    "        exptime = float(sci_hdr['EXPTIME'])\n",
    "        filter_name = sci_hdr['FILTER']\n",
    "        if filter_name not in master_flat.keys():\n",
    "            warnings.warn(f'FITS file {fits_path} uses filter \"{filter_name}\", but no flat is available for that filter. Skipping frame.')\n",
    "            continue\n",
    "\n",
    "        frame = fits.getdata(fits_path).astype(np.float32)\n",
    "\n",
    "        frame -= master_bias\n",
    "        frame -= master_dark * exptime / dark_scale\n",
    "        frame /= master_flat[filter_name]\n",
    "        np.clip(frame, 0, None, out=frame)\n",
    "        frame = frame.astype(sci_frame_dtype)\n",
    "\n",
    "        if fix_lowercase_gaia:\n",
    "            sci_hdr['OBJECT'] = sci_hdr['OBJECT'].replace(\"gaia\", \"Gaia\")\n",
    "        \n",
    "        sci_hdr['BITPIX'] = dtype_to_bitpix[sci_frame_dtype]\n",
    "        if observer_name is not None:\n",
    "            sci_hdr['OBSERVER'] = observer_name\n",
    "        sci_hdr['PROCTIME'] = curr_iso_time_str()\n",
    "        sci_hdr.add_history('Bias subtraction performed')\n",
    "        sci_hdr.add_history('Dark subtraction performed')\n",
    "        sci_hdr.add_history('Flat correction applied')\n",
    "        sci_hdr.remove('BSCALE', ignore_missing=True)\n",
    "        sci_hdr.remove('BZERO', ignore_missing=True)\n",
    "        sci_hdr[\"FILT-1\"] = sci_hdr[\"FILTER\"]\n",
    "        \n",
    "        hdu = fits.PrimaryHDU(frame)\n",
    "        hdu.header = sci_hdr\n",
    "\n",
    "        filename = sci_hdr['OBJECT'] + '_' + sci_hdr['FILTER'] + '_' + sci_hdr['DATE-OBS'] + fits_extension\n",
    "        filename = filename.replace(\"/\", \"_\")\n",
    "        filename = filename.replace(\" \", \"\")\n",
    "        filename = filename.replace(\":\", \"_\")\n",
    "\n",
    "        hdu.writeto(os.path.join(calibrated_path, filename), overwrite=True)\n",
    "\n",
    "\n",
    "if do_image_calibration:\n",
    "    calib_science_frames()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b058fc56-3dde-4540-97a0-b77737d8c236",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de879f94-d1be-4f38-806c-2a64165b0151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_frames():\n",
    "    cal_frames = list_fits_files(calibrated_path, None)\n",
    "    frames_table = Table()\n",
    "    col1 = Column([], dtype='str', name='path')\n",
    "    col2 = Column([], dtype='str', name='target')\n",
    "    col3 = Column([], dtype='str', name='filter')\n",
    "    frames_table.add_columns([col1, col2, col3])\n",
    "    \n",
    "    for fits_path in cal_frames:\n",
    "        hdr = fits.getheader(fits_path)\n",
    "        try:\n",
    "            if hdr['OBJECT'] not in stack_target_names:\n",
    "                continue\n",
    "        except TypeError:\n",
    "            pass\n",
    "        frames_table.add_row((fits_path, hdr['OBJECT'], hdr['FILTER']))\n",
    "\n",
    "    if len(frames_table) == 0:\n",
    "        warnings.warn(\"No images were stacked.\")\n",
    "        return    \n",
    "    frames_table = frames_table.group_by((\"target\", \"filter\"))\n",
    "    for stack_set in frames_table.groups:\n",
    "        frame_datacube = np.empty((len(stack_set), fits_shape[0], fits_shape[1]), dtype=stacked_dtype)\n",
    "        hdr_set = [fits.getheader(stack_set['path'][0])]\n",
    "        frame_datacube[0, :, :] = fits.getdata(stack_set['path'][0])\n",
    "        for i in range(1, len(stack_set)):\n",
    "            image = fits.getdata(stack_set['path'][i]).byteswap().newbyteorder()  # It is necessary to fix endianness of the image\n",
    "            aligned_image, _ = aa.register(image, frame_datacube[0, :, :])\n",
    "            frame_datacube[i, :, :] = aligned_image\n",
    "            hdr_set.append(fits.getheader(stack_set['path'][i]))\n",
    "\n",
    "        exptimes = [hdr['EXPTIME'] for hdr in hdr_set]\n",
    "        if not np.all(np.isclose(exptimes, exptimes[0])):\n",
    "            warnings.warn(f\"Mismatch between exposure times of {hdr_set[0]['OBJECT']}\"\n",
    "        #     for i in range(len(exptimes)):\n",
    "        #         frame_datacube[i, :, :] *= exptimes[0] / exptimes[i]  # Normalize\n",
    "        stacked_frame, _, _ = sigma_clipped_stats(frame_datacube, axis=0)\n",
    "        \n",
    "        stacked_hdr = hdr_set[0].copy()\n",
    "        stacked_hdr.add_history(f\"Stacked {len(stack_set)} frames using astroalign, 3 sigma clipped avg\")\n",
    "        stacked_hdr['NFRAMES'] = len(stack_set)\n",
    "        \n",
    "        total_exptime = np.sum(exptimes)\n",
    "        stacked_hdr['EXPTIME'] = total_exptime\n",
    "        stacked_hdr['EXPOSURE'] = total_exptime\n",
    "        \n",
    "        first_frame_idx = np.argmin([hdr['JD'] for hdr in hdr_set])\n",
    "        last_frame_idx = np.argmax([hdr['JD'] for hdr in hdr_set])\n",
    "        midpoint_jd = (hdr_set[first_frame_idx]['JD'] + hdr_set[last_frame_idx]['JD'] + hdr_set[last_frame_idx]['EXPTIME'] / 86400.) / 2.  # Assuming exptime in seconds\n",
    "        effective_start_jd = midpoint_jd - total_exptime / 2. / 86400.  # Start JD which gives the correct midpoint when calculated using exptime\n",
    "        \n",
    "        stacked_hdr['DATE-OBS'] = (jd_to_iso(effective_start_jd), \"YYYY-MM-DDThh:mm:ss observation start, UT\")  # These are all specific to GoChile's Voyager FITS files.\n",
    "        stacked_hdr['JD'] = (effective_start_jd, \"Julian Date at start of exposure\")                            # Please readjust header handling for other header contents\n",
    "        stacked_hdr['JD-HELIO'] = ((hdr_set[first_frame_idx]['JD-HELIO'] \n",
    "                                    + hdr_set[last_frame_idx]['JD-HELIO'] \n",
    "                                    + hdr_set[last_frame_idx]['EXPTIME'] / 86400.) / 2, \"Heliocentric Julian Date at exposure midpoint\")\n",
    "\n",
    "        sci_hdr[\"FILT-1\"] = sci_hdr[\"FILTER\"]\n",
    "        \n",
    "        stacked_hdr['BITPIX'] = dtype_to_bitpix[stacked_dtype]\n",
    "        stacked_hdr.remove('BSCALE', ignore_missing=True)\n",
    "        stacked_hdr.remove('BZERO', ignore_missing=True)\n",
    "        stacked_hdr['COMMENT'] = \"'DATE-OBS' and 'JD' are effective start times: midpoint - 0.5 exptime\"\n",
    "        \n",
    "        filename = stacked_hdr['OBJECT'] + '_' + stacked_hdr['FILTER'] + '_stacked_' + stacked_hdr['DATE-OBS'] + fits_extension\n",
    "        filename = filename.replace(\"/\", \"_\")\n",
    "        filename = filename.replace(\" \", \"\")  \n",
    "        filename = filename.replace(\":\", \"_\")\n",
    "        hdu = fits.PrimaryHDU(stacked_frame)\n",
    "        hdu.header = stacked_hdr\n",
    "        hdu.writeto(os.path.join(stacked_path, filename), overwrite=True)\n",
    "        print(f\"Stacked {len(stack_set)} frames, target {stacked_hdr['OBJECT']}, filter {stacked_hdr['FILTER']}. Total exptime: {total_exptime} s, {len(stack_set)} frames\")\n",
    "        preview_image(stacked_frame, cmap='gray', sigma_low=3, sigma_high=10, title=f\"{stacked_hdr['OBJECT']}, {stacked_hdr['FILTER']}\")\n",
    "\n",
    "\n",
    "if do_image_stacking:\n",
    "    stack_frames()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40124c4-b0a3-4ce9-b9df-9cc02b58c993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff0a85b-f5b8-4fc8-adae-f380c274136d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
